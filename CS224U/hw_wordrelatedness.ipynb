{"cells":[{"cell_type":"markdown","metadata":{"id":"FS2gMEMkBMVz"},"source":["# Homework and bake-off: Word relatedness"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1K_AmmRrBMV6"},"outputs":[],"source":["__author__ = \"Christopher Potts\"\n","__version__ = \"CS224u, Stanford, Spring 2021\""]},{"cell_type":"markdown","metadata":{"id":"hGEZerVlBMV8"},"source":["## Contents\n","\n","1. [Overview](#Overview)\n","1. [Set-up](#Set-up)\n","1. [Development dataset](#Development-dataset)\n","  1. [Vocabulary](#Vocabulary)\n","  1. [Score distribution](#Score-distribution)\n","  1. [Repeated pairs](#Repeated-pairs)\n","1. [Evaluation](#Evaluation)\n","1. [Error analysis](#Error-analysis)\n","1. [Homework questions](#Homework-questions)\n","  1. [PPMI as a baseline [0.5 points]](#PPMI-as-a-baseline-[0.5-points])\n","  1. [Gigaword with LSA at different dimensions [0.5 points]](#Gigaword-with-LSA-at-different-dimensions-[0.5-points])\n","  1. [t-test reweighting [2 points]](#t-test-reweighting-[2-points])\n","  1. [Pooled BERT representations [1 point]](#Pooled-BERT-representations-[1-point])\n","  1. [Learned distance functions [2 points]](#Learned-distance-functions-[2-points])\n","  1. [Your original system [3 points]](#Your-original-system-[3-points])\n","1. [Bake-off [1 point]](#Bake-off-[1-point])\n","1. [Submission Instruction](#Submission-Instruction)"]},{"cell_type":"markdown","metadata":{"id":"gHEX7xvsBMV9"},"source":["## Overview\n","\n","Word similarity and relatedness datasets have long been used to evaluate distributed representations. This notebook provides code for conducting such analyses with a new word relatedness datasets. It consists of word pairs, each with an associated human-annotated relatedness score. \n","\n","The evaluation metric for each dataset is the [Spearman correlation coefficient $\\rho$](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) between the annotated scores and your distances, as is standard in the literature.\n","\n","This homework ([questions at the bottom of this notebook](#Homework-questions)) asks you to write code that uses the count matrices in `data/vsmdata` to create and evaluate some baseline models. The final question asks you to create your own original system for this task, using any data you wish. This accounts for 9 of the 10 points for this assignment.\n","\n","For the associated bake-off, we will distribute a new dataset, and you will evaluate your original system (no additional training or tuning allowed!) on that datasets and submit your predictions. Systems that enter will receive the additional homework point, and systems that achieve the top score will receive an additional 0.5 points."]},{"cell_type":"markdown","metadata":{"id":"g_07hmfMBMV9"},"source":["## Set-up"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGzClee7BMV-"},"outputs":[],"source":["from collections import defaultdict\n","import csv\n","import itertools\n","import numpy as np\n","import os\n","import pandas as pd\n","import random\n","from scipy.stats import spearmanr\n","\n","import vsm\n","import utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeQe9zYcBMV_"},"outputs":[],"source":["utils.fix_random_seeds()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkKOEw7mBMWA"},"outputs":[],"source":["VSM_HOME = os.path.join('data', 'vsmdata')\n","\n","DATA_HOME = os.path.join('data', 'wordrelatedness')"]},{"cell_type":"markdown","metadata":{"id":"TmE6zUX3BMWB"},"source":["## Development dataset"]},{"cell_type":"markdown","metadata":{"id":"ThhxACULBMWC"},"source":["You can use development dataset freely, since our bake-off evalutions involve a new test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zwk7Y2RdBMWC"},"outputs":[],"source":["dev_df = pd.read_csv(\n","    os.path.join(DATA_HOME, \"cs224u-wordrelatedness-dev.csv\"))"]},{"cell_type":"markdown","metadata":{"id":"-Gw9SDrVBMWD"},"source":["The dataset consists of word pairs with scores:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"-wIhJ-v4BMWD","executionInfo":{"status":"ok","timestamp":1641740392419,"user_tz":-120,"elapsed":27,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"c51d518c-89e0-4cf8-c113-1a647864fd7c"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-2f0f81b1-f19c-4467-9ca5-4cf069a8025d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word1</th>\n","      <th>word2</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>abandon</td>\n","      <td>button</td>\n","      <td>0.18</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>abandon</td>\n","      <td>consigning</td>\n","      <td>0.40</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>abandon</td>\n","      <td>crane</td>\n","      <td>0.16</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>abandon</td>\n","      <td>ditch</td>\n","      <td>0.63</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>abandon</td>\n","      <td>left</td>\n","      <td>0.57</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f0f81b1-f19c-4467-9ca5-4cf069a8025d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2f0f81b1-f19c-4467-9ca5-4cf069a8025d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2f0f81b1-f19c-4467-9ca5-4cf069a8025d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     word1       word2  score\n","0  abandon      button   0.18\n","1  abandon  consigning   0.40\n","2  abandon       crane   0.16\n","3  abandon       ditch   0.63\n","4  abandon        left   0.57"]},"metadata":{},"execution_count":6}],"source":["dev_df.head()"]},{"cell_type":"code","source":["dev_df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"t8y8UA5FMohB","executionInfo":{"status":"ok","timestamp":1641740392421,"user_tz":-120,"elapsed":28,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"7ca3425a-37db-4405-8f98-0397d2016079"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-7dfb7f78-42bf-4bd0-a1f5-eb0a1b3f4ddb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>4756.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.492065</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.272162</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.252525</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.480000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.720000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dfb7f78-42bf-4bd0-a1f5-eb0a1b3f4ddb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7dfb7f78-42bf-4bd0-a1f5-eb0a1b3f4ddb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7dfb7f78-42bf-4bd0-a1f5-eb0a1b3f4ddb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["             score\n","count  4756.000000\n","mean      0.492065\n","std       0.272162\n","min       0.000000\n","25%       0.252525\n","50%       0.480000\n","75%       0.720000\n","max       1.000000"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"VBSOxh88BMWE"},"source":["This gives the number of word pairs in the data:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5frMqZuBMWE","executionInfo":{"status":"ok","timestamp":1641740392424,"user_tz":-120,"elapsed":30,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"36460a86-62dc-4a63-a056-c49abcba95d0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["4756"]},"metadata":{},"execution_count":8}],"source":["dev_df.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"Amn2K5R8BMWE"},"source":["The test set will contain 1500 word pairs with scores of the same type. No word pair in the development set appears in the test set, but some of the individual words are repeated in the test set."]},{"cell_type":"markdown","metadata":{"id":"J_Z3CTpqBMWF"},"source":["### Vocabulary"]},{"cell_type":"markdown","metadata":{"id":"gEaxrsX9BMWF"},"source":["The full vocabulary in the dataframe can be extracted as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SyQKWvb1BMWF"},"outputs":[],"source":["dev_vocab = set(dev_df.word1.values) | set(dev_df.word2.values)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wnb01DEZBMWF","executionInfo":{"status":"ok","timestamp":1641740392428,"user_tz":-120,"elapsed":29,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"f2f1f5eb-8452-4732-92ac-173cca5fc3ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2809"]},"metadata":{},"execution_count":10}],"source":["len(dev_vocab)"]},{"cell_type":"markdown","metadata":{"id":"iMDYhPbIBMWG"},"source":["The vocabulary for the bake-off test is different – it is partly overlapping with the above. If you want to be sure ahead of time that your system has a representation for every word in the dev and test sets, then you can check against the vocabularies of any of the VSMs in `data/vsmdata` (which all have the same vocabulary). For example:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q8mvGqFoBMWG"},"outputs":[],"source":["task_index = pd.read_csv(\n","    os.path.join(VSM_HOME, 'yelp_window5-scaled.csv.gz'),\n","    usecols=[0], index_col=0)\n","\n","full_task_vocab = list(task_index.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaB-cXH9BMWG","executionInfo":{"status":"ok","timestamp":1641740398758,"user_tz":-120,"elapsed":9,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"c93e0b39-c094-46de-9c44-c8fa78c92410"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["6000"]},"metadata":{},"execution_count":12}],"source":["len(full_task_vocab)"]},{"cell_type":"markdown","metadata":{"id":"OcPgSSziBMWH"},"source":["If you can process every one of those words, then you are all set. Alternatively, you can wait to see the test set and make system adjustments to ensure that you can process all those words. This is fine as long as you are not tuning your predictions."]},{"cell_type":"markdown","metadata":{"id":"lYaUXYR6BMWH"},"source":["### Score distribution"]},{"cell_type":"markdown","metadata":{"id":"26dtDTjQBMWH"},"source":["All the scores fall in $[0, 1]$, and the dataset skews towards words with low scores, meaning low relatedness:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"AqDREnckBMWH","executionInfo":{"status":"ok","timestamp":1641740399149,"user_tz":-120,"elapsed":397,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"5bab7dc2-f707-4d96-dcc4-668a93680f81"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["ax = dev_df.plot.hist().set_xlabel(\"Relatedness score\")"]},{"cell_type":"markdown","metadata":{"id":"8NFAaK4QBMWH"},"source":["### Repeated pairs"]},{"cell_type":"markdown","metadata":{"id":"eiyXldtHBMWI"},"source":["The development data has some word pairs with multiple distinct scores in it. Here we create a `pd.Series` that contains these word pairs:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWdKqit5BMWI"},"outputs":[],"source":["repeats = dev_df.groupby(['word1', 'word2']).apply(lambda x: x.score.var())\n","\n","repeats = repeats[repeats > 0].sort_values(ascending=False)\n","\n","repeats.name = 'score variance'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cO4J6TU7BMWI","executionInfo":{"status":"ok","timestamp":1641740399488,"user_tz":-120,"elapsed":19,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"d2775de0-c26b-4636-a956-a2b0bf0f35a6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["279"]},"metadata":{},"execution_count":15}],"source":["repeats.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"Z84nahRoBMWI"},"source":["The `pd.Series` is sorted with the highest variance items at the top:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JCOXXWHBMWI","executionInfo":{"status":"ok","timestamp":1641740399488,"user_tz":-120,"elapsed":17,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"20e82577-2f89-4cb3-a0ce-da9cd572b5dd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["word1    word2     \n","buck     dollar        0.378592\n","furnace  stove         0.274653\n","cash     money         0.247104\n","boxing   round         0.189342\n","money    possession    0.187652\n","Name: score variance, dtype: float64"]},"metadata":{},"execution_count":16}],"source":["repeats.head()"]},{"cell_type":"code","source":["#  dev_df.groupby(['word1', 'word2']).count().sort_values('score', ascending=False)\n","dev_df.query(\"word1 == 'bank' & word2 == 'money'\")['score']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQY27fTALGS6","executionInfo":{"status":"ok","timestamp":1641740399489,"user_tz":-120,"elapsed":12,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"73185dfb-275d-4faa-a43e-593447ad9fce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["476    0.250000\n","477    0.420000\n","478    0.807574\n","479    0.846469\n","Name: score, dtype: float64"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"NpP8Siq8BMWJ"},"source":["Since this is development data, it is up to you how you want to handle these repeats. The test set has no repeated pairs in it."]},{"cell_type":"markdown","metadata":{"id":"y6h0g23_BMWJ"},"source":["## Evaluation"]},{"cell_type":"markdown","metadata":{"id":"ZnUx6XzABMWJ"},"source":["Our evaluation function is `vsm.word_relatedness_evaluation`. Its arguments:\n","    \n","1. A relatedness dataset `pd.DataFrame` – e.g., `dev_df` as given above.\n","1. A VSM `pd.DataFrame` – e.g., `giga5` or some transformation thereof, or a GloVe embedding space, or something you have created on your own. The function checks that you can supply a representation for every word in `dev_df` and raises an exception if you can't.\n","1. Optionally a `distfunc` argument, which defaults to `vsm.cosine`.\n","\n","The function returns a tuple:\n","\n","1. A copy of `dev_df` with a new column giving your predictions.\n","1. The Spearman $\\rho$ value (our primary score).\n","\n","Important note: Internally, `vsm.word_relatedness_evaluation` uses `-distfunc(x1, x2)` as its score, where `x1` and `x2` are vector representations of words. This is because the scores in our data are _positive_ relatedness scores, whereas we are assuming that `distfunc` is a _distance_ function.\n","\n","Here's a simple illustration using one of our count matrices:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pX_9Q-i6BMWK"},"outputs":[],"source":["count_df = pd.read_csv(\n","    os.path.join(VSM_HOME, \"giga_window5-scaled.csv.gz\"), index_col=0)"]},{"cell_type":"code","source":["count_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"T-qhmkpOPzsD","executionInfo":{"status":"ok","timestamp":1641740417004,"user_tz":-120,"elapsed":11,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"92266218-ade0-4d7d-ce48-75e31c1eb8c4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-ab90e000-6c40-4c80-8157-a1abdce3acf4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>):</th>\n","      <th>);</th>\n","      <th>..</th>\n","      <th>...</th>\n","      <th>:(</th>\n","      <th>:)</th>\n","      <th>:/</th>\n","      <th>:D</th>\n","      <th>:|</th>\n","      <th>;p</th>\n","      <th>___</th>\n","      <th>abandon</th>\n","      <th>abc</th>\n","      <th>ability</th>\n","      <th>able</th>\n","      <th>abortion</th>\n","      <th>about</th>\n","      <th>above</th>\n","      <th>abraham</th>\n","      <th>absolute</th>\n","      <th>absolutely</th>\n","      <th>absorbing</th>\n","      <th>abstract</th>\n","      <th>abundance</th>\n","      <th>abuse</th>\n","      <th>ac</th>\n","      <th>accentuate</th>\n","      <th>accept</th>\n","      <th>acceptable</th>\n","      <th>acceptance</th>\n","      <th>accepted</th>\n","      <th>access</th>\n","      <th>accessible</th>\n","      <th>accident</th>\n","      <th>acclaim</th>\n","      <th>accommodate</th>\n","      <th>accommodating</th>\n","      <th>accommodation</th>\n","      <th>accompanied</th>\n","      <th>accompany</th>\n","      <th>...</th>\n","      <th>written</th>\n","      <th>wrong</th>\n","      <th>wrote</th>\n","      <th>yacht</th>\n","      <th>yard</th>\n","      <th>yards</th>\n","      <th>yarn</th>\n","      <th>yeah</th>\n","      <th>year</th>\n","      <th>year's</th>\n","      <th>year-old</th>\n","      <th>years</th>\n","      <th>yeast</th>\n","      <th>yell</th>\n","      <th>yellow</th>\n","      <th>yen</th>\n","      <th>yes</th>\n","      <th>yesterday</th>\n","      <th>yet</th>\n","      <th>yield</th>\n","      <th>yielding</th>\n","      <th>yin</th>\n","      <th>yogurt</th>\n","      <th>york</th>\n","      <th>you</th>\n","      <th>you'd</th>\n","      <th>you'll</th>\n","      <th>you're</th>\n","      <th>you've</th>\n","      <th>young</th>\n","      <th>younger</th>\n","      <th>your</th>\n","      <th>yourself</th>\n","      <th>youth</th>\n","      <th>zebra</th>\n","      <th>zero</th>\n","      <th>zinc</th>\n","      <th>zombie</th>\n","      <th>zone</th>\n","      <th>zoo</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>):</th>\n","      <td>4.300000</td>\n","      <td>8.100000</td>\n","      <td>7.700000</td>\n","      <td>113.766667</td>\n","      <td>2.666667</td>\n","      <td>1.116667</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>52.766667</td>\n","      <td>0.000000</td>\n","      <td>70.816667</td>\n","      <td>0.500000</td>\n","      <td>1.066667</td>\n","      <td>2.533333</td>\n","      <td>109.100000</td>\n","      <td>9.750000</td>\n","      <td>0.900000</td>\n","      <td>0.000000</td>\n","      <td>3.250000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.50</td>\n","      <td>1.200000</td>\n","      <td>18.850000</td>\n","      <td>0.0</td>\n","      <td>2.500000</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>4.166667</td>\n","      <td>1.200000</td>\n","      <td>0.166667</td>\n","      <td>1.200000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.700000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>4.100000</td>\n","      <td>3.433333</td>\n","      <td>3.216667</td>\n","      <td>1.566667</td>\n","      <td>3.083333</td>\n","      <td>37.750000</td>\n","      <td>0.000000</td>\n","      <td>11.200000</td>\n","      <td>59.700000</td>\n","      <td>10.033333</td>\n","      <td>14.183333</td>\n","      <td>94.983333</td>\n","      <td>0.70</td>\n","      <td>0.000000</td>\n","      <td>4.150000</td>\n","      <td>2.966667</td>\n","      <td>25.666667</td>\n","      <td>41.883333</td>\n","      <td>14.400000</td>\n","      <td>1.400000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.833333</td>\n","      <td>77.866667</td>\n","      <td>528.383333</td>\n","      <td>1.083333</td>\n","      <td>5.366667</td>\n","      <td>62.583333</td>\n","      <td>13.850000</td>\n","      <td>28.633333</td>\n","      <td>2.850000</td>\n","      <td>147.633333</td>\n","      <td>8.483333</td>\n","      <td>4.500000</td>\n","      <td>0.000000</td>\n","      <td>2.733333</td>\n","      <td>0.200000</td>\n","      <td>0.333333</td>\n","      <td>344.066667</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <th>);</th>\n","      <td>8.100000</td>\n","      <td>1092.400000</td>\n","      <td>0.650000</td>\n","      <td>52.783333</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.700000</td>\n","      <td>0.000000</td>\n","      <td>47.366667</td>\n","      <td>2.616667</td>\n","      <td>1.066667</td>\n","      <td>1.833333</td>\n","      <td>149.716667</td>\n","      <td>18.816667</td>\n","      <td>9.066667</td>\n","      <td>0.700000</td>\n","      <td>1.366667</td>\n","      <td>0.500000</td>\n","      <td>1.833333</td>\n","      <td>0.00</td>\n","      <td>1.283333</td>\n","      <td>60.166667</td>\n","      <td>0.0</td>\n","      <td>0.900000</td>\n","      <td>1.866667</td>\n","      <td>1.200000</td>\n","      <td>4.100000</td>\n","      <td>6.816667</td>\n","      <td>0.166667</td>\n","      <td>3.250000</td>\n","      <td>0.000000</td>\n","      <td>0.616667</td>\n","      <td>0.583333</td>\n","      <td>0.250000</td>\n","      <td>0.650000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>7.816667</td>\n","      <td>4.400000</td>\n","      <td>6.133333</td>\n","      <td>3.316667</td>\n","      <td>5.583333</td>\n","      <td>28.833333</td>\n","      <td>0.250000</td>\n","      <td>0.416667</td>\n","      <td>71.383333</td>\n","      <td>5.850000</td>\n","      <td>13.550000</td>\n","      <td>73.116667</td>\n","      <td>1.00</td>\n","      <td>0.250000</td>\n","      <td>8.350000</td>\n","      <td>7.466667</td>\n","      <td>8.000000</td>\n","      <td>1.500000</td>\n","      <td>18.850000</td>\n","      <td>1.066667</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>0.166667</td>\n","      <td>172.800000</td>\n","      <td>110.633333</td>\n","      <td>1.233333</td>\n","      <td>4.350000</td>\n","      <td>10.250000</td>\n","      <td>1.400000</td>\n","      <td>58.200000</td>\n","      <td>7.100000</td>\n","      <td>44.400000</td>\n","      <td>3.333333</td>\n","      <td>7.116667</td>\n","      <td>0.400000</td>\n","      <td>1.616667</td>\n","      <td>1.000000</td>\n","      <td>0.500000</td>\n","      <td>11.516667</td>\n","      <td>1.250000</td>\n","    </tr>\n","    <tr>\n","      <th>..</th>\n","      <td>7.700000</td>\n","      <td>0.650000</td>\n","      <td>18900.766667</td>\n","      <td>12657.800000</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.933333</td>\n","      <td>0.166667</td>\n","      <td>2.033333</td>\n","      <td>0.600000</td>\n","      <td>2.433333</td>\n","      <td>3.983333</td>\n","      <td>59.900000</td>\n","      <td>3.050000</td>\n","      <td>5.583333</td>\n","      <td>0.333333</td>\n","      <td>0.833333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>1.100000</td>\n","      <td>0.833333</td>\n","      <td>0.0</td>\n","      <td>3.650000</td>\n","      <td>0.950000</td>\n","      <td>2.000000</td>\n","      <td>0.750000</td>\n","      <td>3.483333</td>\n","      <td>0.000000</td>\n","      <td>3.450000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.600000</td>\n","      <td>0.583333</td>\n","      <td>...</td>\n","      <td>19.333333</td>\n","      <td>2.250000</td>\n","      <td>2.216667</td>\n","      <td>0.333333</td>\n","      <td>0.583333</td>\n","      <td>4.250000</td>\n","      <td>0.000000</td>\n","      <td>0.416667</td>\n","      <td>64.216667</td>\n","      <td>4.366667</td>\n","      <td>5.883333</td>\n","      <td>48.416667</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>4.633333</td>\n","      <td>1.750000</td>\n","      <td>6.100000</td>\n","      <td>8.833333</td>\n","      <td>1.933333</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>562.566667</td>\n","      <td>69.616667</td>\n","      <td>0.200000</td>\n","      <td>1.900000</td>\n","      <td>9.750000</td>\n","      <td>1.200000</td>\n","      <td>75.533333</td>\n","      <td>1.166667</td>\n","      <td>29.883333</td>\n","      <td>0.833333</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.916667</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>2.983333</td>\n","      <td>1.083333</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>113.766667</td>\n","      <td>52.783333</td>\n","      <td>12657.800000</td>\n","      <td>131656.033333</td>\n","      <td>0.866667</td>\n","      <td>0.500000</td>\n","      <td>0.85</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>294.200000</td>\n","      <td>33.550000</td>\n","      <td>33.166667</td>\n","      <td>117.633333</td>\n","      <td>293.083333</td>\n","      <td>39.250000</td>\n","      <td>3188.216667</td>\n","      <td>183.900000</td>\n","      <td>18.266667</td>\n","      <td>60.516667</td>\n","      <td>189.116667</td>\n","      <td>1.600000</td>\n","      <td>4.550000</td>\n","      <td>2.60</td>\n","      <td>52.633333</td>\n","      <td>1.000000</td>\n","      <td>0.5</td>\n","      <td>207.516667</td>\n","      <td>58.633333</td>\n","      <td>26.983333</td>\n","      <td>81.333333</td>\n","      <td>128.700000</td>\n","      <td>7.750000</td>\n","      <td>70.216667</td>\n","      <td>1.666667</td>\n","      <td>16.433333</td>\n","      <td>3.866667</td>\n","      <td>10.650000</td>\n","      <td>19.466667</td>\n","      <td>12.933333</td>\n","      <td>...</td>\n","      <td>181.683333</td>\n","      <td>285.016667</td>\n","      <td>94.283333</td>\n","      <td>3.733333</td>\n","      <td>29.116667</td>\n","      <td>66.750000</td>\n","      <td>3.500000</td>\n","      <td>161.900000</td>\n","      <td>1026.416667</td>\n","      <td>81.033333</td>\n","      <td>75.050000</td>\n","      <td>1222.716667</td>\n","      <td>1.25</td>\n","      <td>11.983333</td>\n","      <td>32.916667</td>\n","      <td>57.150000</td>\n","      <td>451.283333</td>\n","      <td>109.000000</td>\n","      <td>474.800000</td>\n","      <td>31.000000</td>\n","      <td>3.566667</td>\n","      <td>3.333333</td>\n","      <td>0.833333</td>\n","      <td>1173.816667</td>\n","      <td>7347.250000</td>\n","      <td>49.383333</td>\n","      <td>109.316667</td>\n","      <td>604.050000</td>\n","      <td>159.800000</td>\n","      <td>534.966667</td>\n","      <td>40.333333</td>\n","      <td>2187.066667</td>\n","      <td>89.750000</td>\n","      <td>42.000000</td>\n","      <td>8.200000</td>\n","      <td>30.683333</td>\n","      <td>0.666667</td>\n","      <td>2.333333</td>\n","      <td>79.233333</td>\n","      <td>11.083333</td>\n","    </tr>\n","    <tr>\n","      <th>:(</th>\n","      <td>2.666667</td>\n","      <td>0.666667</td>\n","      <td>0.500000</td>\n","      <td>0.866667</td>\n","      <td>0.000000</td>\n","      <td>0.333333</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.200000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.416667</td>\n","      <td>0.750000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.583333</td>\n","      <td>0.00</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.916667</td>\n","      <td>0.000000</td>\n","      <td>3.433333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.500000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.750000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>4.766667</td>\n","      <td>0.166667</td>\n","      <td>0.333333</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>zero</th>\n","      <td>2.733333</td>\n","      <td>1.616667</td>\n","      <td>0.916667</td>\n","      <td>30.683333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.033333</td>\n","      <td>1.333333</td>\n","      <td>0.600000</td>\n","      <td>10.966667</td>\n","      <td>10.600000</td>\n","      <td>1.450000</td>\n","      <td>199.683333</td>\n","      <td>183.750000</td>\n","      <td>0.666667</td>\n","      <td>179.866667</td>\n","      <td>95.750000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>13.133333</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>7.783333</td>\n","      <td>1.933333</td>\n","      <td>2.500000</td>\n","      <td>0.666667</td>\n","      <td>9.066667</td>\n","      <td>0.000000</td>\n","      <td>5.533333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.116667</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>6.416667</td>\n","      <td>6.766667</td>\n","      <td>4.466667</td>\n","      <td>0.000000</td>\n","      <td>2.983333</td>\n","      <td>53.383333</td>\n","      <td>0.200000</td>\n","      <td>0.250000</td>\n","      <td>233.816667</td>\n","      <td>10.133333</td>\n","      <td>4.133333</td>\n","      <td>116.483333</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>1.266667</td>\n","      <td>6.466667</td>\n","      <td>4.500000</td>\n","      <td>1.283333</td>\n","      <td>21.150000</td>\n","      <td>33.283333</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>71.650000</td>\n","      <td>178.600000</td>\n","      <td>1.450000</td>\n","      <td>3.083333</td>\n","      <td>18.183333</td>\n","      <td>4.050000</td>\n","      <td>4.433333</td>\n","      <td>0.666667</td>\n","      <td>26.516667</td>\n","      <td>1.533333</td>\n","      <td>1.600000</td>\n","      <td>0.000000</td>\n","      <td>270.333333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>6.900000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>zinc</th>\n","      <td>0.200000</td>\n","      <td>1.000000</td>\n","      <td>0.250000</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>16.083333</td>\n","      <td>1.750000</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>1.066667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>16.600000</td>\n","      <td>0.000000</td>\n","      <td>0.866667</td>\n","      <td>4.933333</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1.716667</td>\n","      <td>0.000000</td>\n","      <td>3.466667</td>\n","      <td>1.750000</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.866667</td>\n","      <td>5.733333</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.200000</td>\n","      <td>0.000000</td>\n","      <td>7.116667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>24.966667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>zombie</th>\n","      <td>0.333333</td>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","      <td>2.333333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.200000</td>\n","      <td>0.000000</td>\n","      <td>0.200000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>13.450000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","      <td>0.766667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.266667</td>\n","      <td>1.333333</td>\n","      <td>0.533333</td>\n","      <td>2.283333</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.416667</td>\n","      <td>0.000000</td>\n","      <td>1.083333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.566667</td>\n","      <td>10.116667</td>\n","      <td>0.200000</td>\n","      <td>1.033333</td>\n","      <td>0.366667</td>\n","      <td>0.866667</td>\n","      <td>0.500000</td>\n","      <td>0.200000</td>\n","      <td>2.700000</td>\n","      <td>0.000000</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.700000</td>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>zone</th>\n","      <td>344.066667</td>\n","      <td>11.516667</td>\n","      <td>2.983333</td>\n","      <td>79.233333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>158.133333</td>\n","      <td>13.883333</td>\n","      <td>2.316667</td>\n","      <td>8.683333</td>\n","      <td>21.200000</td>\n","      <td>9.983333</td>\n","      <td>330.950000</td>\n","      <td>203.516667</td>\n","      <td>0.700000</td>\n","      <td>1.566667</td>\n","      <td>3.100000</td>\n","      <td>0.583333</td>\n","      <td>0.000000</td>\n","      <td>1.95</td>\n","      <td>1.783333</td>\n","      <td>2.650000</td>\n","      <td>0.0</td>\n","      <td>8.450000</td>\n","      <td>1.600000</td>\n","      <td>0.800000</td>\n","      <td>3.766667</td>\n","      <td>29.600000</td>\n","      <td>1.950000</td>\n","      <td>11.000000</td>\n","      <td>0.800000</td>\n","      <td>0.666667</td>\n","      <td>0.500000</td>\n","      <td>0.333333</td>\n","      <td>2.750000</td>\n","      <td>4.066667</td>\n","      <td>...</td>\n","      <td>6.516667</td>\n","      <td>9.616667</td>\n","      <td>5.600000</td>\n","      <td>1.366667</td>\n","      <td>138.233333</td>\n","      <td>138.566667</td>\n","      <td>0.333333</td>\n","      <td>1.600000</td>\n","      <td>151.633333</td>\n","      <td>9.433333</td>\n","      <td>8.100000</td>\n","      <td>98.733333</td>\n","      <td>0.00</td>\n","      <td>0.200000</td>\n","      <td>15.116667</td>\n","      <td>5.516667</td>\n","      <td>6.616667</td>\n","      <td>7.183333</td>\n","      <td>39.250000</td>\n","      <td>1.200000</td>\n","      <td>3.450000</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>29.816667</td>\n","      <td>254.450000</td>\n","      <td>2.033333</td>\n","      <td>7.566667</td>\n","      <td>829.183333</td>\n","      <td>15.766667</td>\n","      <td>20.733333</td>\n","      <td>1.000000</td>\n","      <td>112.033333</td>\n","      <td>3.850000</td>\n","      <td>2.333333</td>\n","      <td>0.666667</td>\n","      <td>6.900000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>248.466667</td>\n","      <td>0.816667</td>\n","    </tr>\n","    <tr>\n","      <th>zoo</th>\n","      <td>0.700000</td>\n","      <td>1.250000</td>\n","      <td>1.083333</td>\n","      <td>11.083333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.566667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>8.366667</td>\n","      <td>0.000000</td>\n","      <td>79.300000</td>\n","      <td>5.433333</td>\n","      <td>0.250000</td>\n","      <td>1.000000</td>\n","      <td>1.116667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.20</td>\n","      <td>0.800000</td>\n","      <td>0.166667</td>\n","      <td>0.0</td>\n","      <td>1.500000</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.333333</td>\n","      <td>1.000000</td>\n","      <td>0.166667</td>\n","      <td>1.350000</td>\n","      <td>0.000000</td>\n","      <td>1.150000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.500000</td>\n","      <td>0.783333</td>\n","      <td>...</td>\n","      <td>0.533333</td>\n","      <td>1.250000</td>\n","      <td>1.650000</td>\n","      <td>0.000000</td>\n","      <td>1.766667</td>\n","      <td>0.200000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>42.100000</td>\n","      <td>1.466667</td>\n","      <td>26.733333</td>\n","      <td>61.666667</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.750000</td>\n","      <td>0.200000</td>\n","      <td>1.350000</td>\n","      <td>2.700000</td>\n","      <td>6.783333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.033333</td>\n","      <td>0.333333</td>\n","      <td>43.800000</td>\n","      <td>43.900000</td>\n","      <td>0.166667</td>\n","      <td>1.300000</td>\n","      <td>1.333333</td>\n","      <td>1.366667</td>\n","      <td>11.200000</td>\n","      <td>1.000000</td>\n","      <td>9.383333</td>\n","      <td>0.250000</td>\n","      <td>0.400000</td>\n","      <td>1.500000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.816667</td>\n","      <td>141.133333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6000 rows × 6000 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab90e000-6c40-4c80-8157-a1abdce3acf4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ab90e000-6c40-4c80-8157-a1abdce3acf4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ab90e000-6c40-4c80-8157-a1abdce3acf4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                ):           );            ..  ...    zombie        zone         zoo\n","):        4.300000     8.100000      7.700000  ...  0.333333  344.066667    0.700000\n",");        8.100000  1092.400000      0.650000  ...  0.500000   11.516667    1.250000\n","..        7.700000     0.650000  18900.766667  ...  0.000000    2.983333    1.083333\n","...     113.766667    52.783333  12657.800000  ...  2.333333   79.233333   11.083333\n",":(        2.666667     0.666667      0.500000  ...  0.000000    0.000000    0.000000\n","...            ...          ...           ...  ...       ...         ...         ...\n","zero      2.733333     1.616667      0.916667  ...  0.000000    6.900000    0.000000\n","zinc      0.200000     1.000000      0.250000  ...  0.000000    0.000000    0.000000\n","zombie    0.333333     0.500000      0.000000  ...  4.700000    0.500000    0.000000\n","zone    344.066667    11.516667      2.983333  ...  0.500000  248.466667    0.816667\n","zoo       0.700000     1.250000      1.083333  ...  0.000000    0.816667  141.133333\n","\n","[6000 rows x 6000 columns]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxOEZqqIBMWK"},"outputs":[],"source":["count_pred_df, count_rho = vsm.word_relatedness_evaluation(dev_df, count_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjVoDbXXBMWK","executionInfo":{"status":"ok","timestamp":1641740419566,"user_tz":-120,"elapsed":11,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"6875e2ab-b15c-49fa-b78d-8319a2b6ca7b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.277636645128081"]},"metadata":{},"execution_count":21}],"source":["count_rho"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"gwQ9LzD3BMWK","executionInfo":{"status":"ok","timestamp":1641740419567,"user_tz":-120,"elapsed":10,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"4ece3d38-d719-42ee-f1d7-39c15bb592b2"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-690a435a-ce33-4165-b82b-b2dcfb6f3fa6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word1</th>\n","      <th>word2</th>\n","      <th>score</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>abandon</td>\n","      <td>button</td>\n","      <td>0.18</td>\n","      <td>-0.336291</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>abandon</td>\n","      <td>consigning</td>\n","      <td>0.40</td>\n","      <td>-0.085422</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>abandon</td>\n","      <td>crane</td>\n","      <td>0.16</td>\n","      <td>-0.307229</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>abandon</td>\n","      <td>ditch</td>\n","      <td>0.63</td>\n","      <td>-0.211550</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>abandon</td>\n","      <td>left</td>\n","      <td>0.57</td>\n","      <td>-0.337866</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-690a435a-ce33-4165-b82b-b2dcfb6f3fa6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-690a435a-ce33-4165-b82b-b2dcfb6f3fa6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-690a435a-ce33-4165-b82b-b2dcfb6f3fa6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     word1       word2  score  prediction\n","0  abandon      button   0.18   -0.336291\n","1  abandon  consigning   0.40   -0.085422\n","2  abandon       crane   0.16   -0.307229\n","3  abandon       ditch   0.63   -0.211550\n","4  abandon        left   0.57   -0.337866"]},"metadata":{},"execution_count":22}],"source":["count_pred_df.head()"]},{"cell_type":"markdown","metadata":{"id":"k2J9iAPgBMWL"},"source":["It's instructive to compare this against a truly random system, which we can create by simply having a custom distance function that returns a random number in [0, 1] for each example, making no use of the VSM itself:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0iZYJAZuBMWL"},"outputs":[],"source":["def random_scorer(x1, x2):\n","    \"\"\"`x1` and `x2` are vectors, to conform to the requirements\n","    of `vsm.word_relatedness_evaluation`, but this function just\n","    returns a random number in [0, 1].\"\"\"\n","    return random.random()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2t6PPeo9BMWL","executionInfo":{"status":"ok","timestamp":1641740420729,"user_tz":-120,"elapsed":1170,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"9cdf6212-76ba-41d1-b7f7-f00bc6884e8a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["-0.0005943310475099998"]},"metadata":{},"execution_count":24}],"source":["random_pred_df, random_rho = vsm.word_relatedness_evaluation(\n","    dev_df, count_df, distfunc=random_scorer)\n","\n","random_rho"]},{"cell_type":"markdown","metadata":{"id":"leMazTqnBMWL"},"source":["This is a truly baseline system!"]},{"cell_type":"markdown","metadata":{"id":"vIJIybJSBMWL"},"source":["## Error analysis\n","\n","For error analysis, we can look at the words with the largest delta between the gold score and the distance value in our VSM. We do these comparisons based on ranks, just as with our primary metric (Spearman $\\rho$), and we normalize both rankings so that they have a comparable number of levels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xe8_J9jBMWL"},"outputs":[],"source":["def error_analysis(pred_df):\n","    pred_df = pred_df.copy()\n","    pred_df['relatedness_rank'] = _normalized_ranking(pred_df.prediction)\n","    pred_df['score_rank'] = _normalized_ranking(pred_df.score)\n","    pred_df['error'] =  abs(pred_df['relatedness_rank'] - pred_df['score_rank'])\n","    return pred_df.sort_values('error')\n","\n","\n","def _normalized_ranking(series):\n","    ranks = series.rank(method='dense')\n","    return ranks / ranks.sum()"]},{"cell_type":"markdown","metadata":{"id":"g2z_VH4uBMWM"},"source":["Best predictions:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"izEoByt9BMWM","executionInfo":{"status":"ok","timestamp":1641740420731,"user_tz":-120,"elapsed":13,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"5fa91f0d-eed1-4f37-8289-50fdc71b979e"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-ccebbf91-e9c5-44c2-8cd5-1f6c45dc1d8c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word1</th>\n","      <th>word2</th>\n","      <th>score</th>\n","      <th>prediction</th>\n","      <th>relatedness_rank</th>\n","      <th>score_rank</th>\n","      <th>error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3121</th>\n","      <td>health</td>\n","      <td>psychology</td>\n","      <td>0.325</td>\n","      <td>-0.238147</td>\n","      <td>0.000127</td>\n","      <td>0.000127</td>\n","      <td>1.781311e-08</td>\n","    </tr>\n","    <tr>\n","      <th>2984</th>\n","      <td>grey</td>\n","      <td>purple</td>\n","      <td>0.660</td>\n","      <td>-0.125642</td>\n","      <td>0.000283</td>\n","      <td>0.000283</td>\n","      <td>4.916564e-08</td>\n","    </tr>\n","    <tr>\n","      <th>2628</th>\n","      <td>flower</td>\n","      <td>interior</td>\n","      <td>0.280</td>\n","      <td>-0.262006</td>\n","      <td>0.000106</td>\n","      <td>0.000106</td>\n","      <td>5.701279e-08</td>\n","    </tr>\n","    <tr>\n","      <th>239</th>\n","      <td>appearance</td>\n","      <td>image</td>\n","      <td>0.535</td>\n","      <td>-0.166412</td>\n","      <td>0.000218</td>\n","      <td>0.000218</td>\n","      <td>6.749182e-08</td>\n","    </tr>\n","    <tr>\n","      <th>333</th>\n","      <td>asphalt</td>\n","      <td>road</td>\n","      <td>0.800</td>\n","      <td>-0.068795</td>\n","      <td>0.000367</td>\n","      <td>0.000367</td>\n","      <td>1.064953e-07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccebbf91-e9c5-44c2-8cd5-1f6c45dc1d8c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ccebbf91-e9c5-44c2-8cd5-1f6c45dc1d8c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ccebbf91-e9c5-44c2-8cd5-1f6c45dc1d8c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["           word1       word2  score  ...  relatedness_rank  score_rank         error\n","3121      health  psychology  0.325  ...          0.000127    0.000127  1.781311e-08\n","2984        grey      purple  0.660  ...          0.000283    0.000283  4.916564e-08\n","2628      flower    interior  0.280  ...          0.000106    0.000106  5.701279e-08\n","239   appearance       image  0.535  ...          0.000218    0.000218  6.749182e-08\n","333      asphalt        road  0.800  ...          0.000367    0.000367  1.064953e-07\n","\n","[5 rows x 7 columns]"]},"metadata":{},"execution_count":26}],"source":["error_analysis(count_pred_df).head()"]},{"cell_type":"markdown","metadata":{"id":"wWYp3g84BMWM"},"source":["Worst predictions:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"fTpgMxXPBMWM","executionInfo":{"status":"ok","timestamp":1641740420731,"user_tz":-120,"elapsed":12,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"65f44032-b16d-4d43-d194-011874be1b45"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-8311d95d-a1cc-4953-8330-73318b1ea934\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word1</th>\n","      <th>word2</th>\n","      <th>score</th>\n","      <th>prediction</th>\n","      <th>relatedness_rank</th>\n","      <th>score_rank</th>\n","      <th>error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4643</th>\n","      <td>submit</td>\n","      <td>yield</td>\n","      <td>0.916750</td>\n","      <td>-0.473501</td>\n","      <td>1.440789e-05</td>\n","      <td>0.000423</td>\n","      <td>0.000409</td>\n","    </tr>\n","    <tr>\n","      <th>1010</th>\n","      <td>bulletin</td>\n","      <td>news</td>\n","      <td>0.925926</td>\n","      <td>-0.503304</td>\n","      <td>1.082946e-05</td>\n","      <td>0.000425</td>\n","      <td>0.000415</td>\n","    </tr>\n","    <tr>\n","      <th>4091</th>\n","      <td>photo</td>\n","      <td>picture</td>\n","      <td>0.920000</td>\n","      <td>-0.632888</td>\n","      <td>2.165892e-06</td>\n","      <td>0.000424</td>\n","      <td>0.000421</td>\n","    </tr>\n","    <tr>\n","      <th>3001</th>\n","      <td>grow</td>\n","      <td>sprouting</td>\n","      <td>0.950000</td>\n","      <td>-0.518391</td>\n","      <td>9.134414e-06</td>\n","      <td>0.000431</td>\n","      <td>0.000422</td>\n","    </tr>\n","    <tr>\n","      <th>4338</th>\n","      <td>repeating</td>\n","      <td>replicate</td>\n","      <td>0.925000</td>\n","      <td>-0.728052</td>\n","      <td>3.766768e-07</td>\n","      <td>0.000425</td>\n","      <td>0.000425</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8311d95d-a1cc-4953-8330-73318b1ea934')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8311d95d-a1cc-4953-8330-73318b1ea934 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8311d95d-a1cc-4953-8330-73318b1ea934');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          word1      word2     score  ...  relatedness_rank  score_rank     error\n","4643     submit      yield  0.916750  ...      1.440789e-05    0.000423  0.000409\n","1010   bulletin       news  0.925926  ...      1.082946e-05    0.000425  0.000415\n","4091      photo    picture  0.920000  ...      2.165892e-06    0.000424  0.000421\n","3001       grow  sprouting  0.950000  ...      9.134414e-06    0.000431  0.000422\n","4338  repeating  replicate  0.925000  ...      3.766768e-07    0.000425  0.000425\n","\n","[5 rows x 7 columns]"]},"metadata":{},"execution_count":27}],"source":["error_analysis(count_pred_df).tail()"]},{"cell_type":"markdown","metadata":{"id":"ud3HREt9BMWM"},"source":["## Homework questions\n","\n","Please embed your homework responses in this notebook, and do not delete any cells from the notebook. (You are free to add as many cells as you like as part of your responses.)"]},{"cell_type":"markdown","metadata":{"id":"eIkAzUyuBMWM"},"source":["### PPMI as a baseline [0.5 points]"]},{"cell_type":"markdown","metadata":{"id":"tKC2E8JFBMWN"},"source":["The insight behind PPMI is a recurring theme in word representation learning, so it is a natural baseline for our task. This question asks you to write code for conducting such experiments.\n","\n","Your task: write a function called `run_giga_ppmi_baseline` that does the following:\n","\n","1. Reads the Gigaword count matrix with a window of 20 and a flat scaling function into a `pd.DataFrame`, as is done in the VSM notebooks. The file is `data/vsmdata/giga_window20-flat.csv.gz`, and the VSM notebooks provide examples of the needed code.\n","1. Reweights this count matrix with PPMI.\n","1. Evaluates this reweighted matrix using `vsm.word_relatedness_evaluation` on `dev_df` as defined above, with `distfunc` set to the default of `vsm.cosine`.\n","1. Returns the return value of this call to `vsm.word_relatedness_evaluation`.\n","\n","The goal of this question is to help you get more familiar with the code in `vsm` and the function `vsm.word_relatedness_evaluation`.\n","\n","The function `test_run_giga_ppmi_baseline` can be used to test that you've implemented this specification correctly."]},{"cell_type":"code","source":["ppmi_df = pd.read_csv(\n","        os.path.join(VSM_HOME, \"giga_window20-flat.csv.gz\"), index_col=0)"],"metadata":{"id":"FwHKrEUpFgD7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oGQpn9VPBMWN"},"outputs":[],"source":["def run_giga_ppmi_baseline():\n","    \"\"\"\n","    get reweighted matrix by applying ppmi on count matrix.\n","    Evaluate ppmi count matrix vs true scores and return the dataframe and the rho coefficient\n","    \n","    Parameters\n","    -----------\n","\n","    Returns\n","    -----------\n","    pd.DataFrame\n","        a DataFrame with were in each row we compare against two words its true similarity score,\n","        and its predicted value (by the ppmi on word counts matrix)\n","\n","    float\n","        Spearman coefficient between prediction and true values (from dev_df)\n","    \"\"\"\n","    ppmi_df = pd.read_csv(\n","        os.path.join(VSM_HOME, \"giga_window20-flat.csv.gz\"), index_col=0)\n","    ppmi_df = vsm.pmi(ppmi_df, positive=True)  # get ppmi weights\n","    ppmi_pred_df, ppmi_rho = vsm.word_relatedness_evaluation(dev_df, ppmi_df)  # default distfunc=consine\n","    return ppmi_pred_df, ppmi_rho\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1cFq2hSgBMWN"},"outputs":[],"source":["def test_run_giga_ppmi_baseline(func):\n","    \"\"\"`func` should be `run_giga_ppmi_baseline\"\"\"\n","    pred_df, rho = func()\n","    rho = round(rho, 3)\n","    expected = 0.586\n","    assert rho == expected, \\\n","        \"Expected rho of {}; got {}\".format(expected, rho)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7vdP2tQ_BMWN"},"outputs":[],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    test_run_giga_ppmi_baseline(run_giga_ppmi_baseline)"]},{"cell_type":"code","source":["ppmi_pred_df, ppmi_rho = run_giga_ppmi_baseline()\n","ppmi_pred_df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rz7A1-_uJiKF","executionInfo":{"status":"ok","timestamp":1641724464258,"user_tz":-120,"elapsed":18883,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"67a65b0a-32a6-4934-b5cf-4b06f86035e9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['word1', 'word2', 'score', 'prediction'], dtype='object')"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"JhHEZdmoBMWN"},"source":["### Gigaword with LSA at different dimensions [0.5 points]"]},{"cell_type":"markdown","metadata":{"id":"DFkhsz3bBMWO"},"source":["We might expect PPMI and LSA to form a solid pipeline that combines the strengths of PPMI with those of dimensionality reduction. However, LSA has a hyper-parameter $k$ – the dimensionality of the final representations – that will impact performance. This problem asks you to create code that will help you explore this approach.\n","\n","Your task: write a wrapper function `run_ppmi_lsa_pipeline` that does the following:\n","\n","1. Takes as input a count `pd.DataFrame` and an LSA parameter `k`.\n","1. Reweights the count matrix with PPMI.\n","1. Applies LSA with dimensionality `k`.\n","1. Evaluates this reweighted matrix using `vsm.word_relatedness_evaluation` with `dev_df` as defined above. The return value of `run_ppmi_lsa_pipeline` should be the return value of this call to `vsm.word_relatedness_evaluation`.\n","\n","The goal of this question is to help you get a feel for how LSA can contribute to this problem. \n","\n","The  function `test_run_ppmi_lsa_pipeline` will test your function on the count matrix in `data/vsmdata/giga_window20-flat.csv.gz`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPEgLyojBMWO"},"outputs":[],"source":["def run_ppmi_lsa_pipeline(count_df, k):\n","    ppmi_df = vsm.pmi(count_df, positive=True)  # get ppmi weights\n","    lsa_df = vsm.lsa(ppmi_df, k=k)  # appy dimensionality reduction with LSA\n","    lsa_pred_df, lsa_rho = vsm.word_relatedness_evaluation(dev_df, lsa_df)  # default distfunc=consine\n","    return lsa_pred_df, lsa_rho\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JzQbOTeBMWO"},"outputs":[],"source":["def test_run_ppmi_lsa_pipeline(func):\n","    \"\"\"`func` should be `run_ppmi_lsa_pipeline`\"\"\"\n","    giga20 = pd.read_csv(\n","        os.path.join(VSM_HOME, \"giga_window20-flat.csv.gz\"), index_col=0)\n","    pred_df, rho = func(giga20, k=10)\n","    rho = round(rho, 3)\n","    expected = 0.545\n","    assert rho == expected,\\\n","        \"Expected rho of {}; got {}\".format(expected, rho)\n","    # print(f' rho = {rho}\\texpected = {expected}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCKc-Eq2BMWO"},"outputs":[],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    test_run_ppmi_lsa_pipeline(run_ppmi_lsa_pipeline)"]},{"cell_type":"code","source":["count_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHg2HMUmMULu","executionInfo":{"status":"ok","timestamp":1641715541009,"user_tz":-120,"elapsed":22,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"7fd8dc43-3d31-46dc-acfe-d76530d31d42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6000, 6000)"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"GAz4eJfsBMWO"},"source":["### t-test reweighting [2 points]"]},{"cell_type":"markdown","metadata":{"id":"En2QBQeRBMWO"},"source":["The t-test statistic can be thought of as a reweighting scheme. For a count matrix $X$, row index $i$, and column index $j$:\n","\n","$$\\textbf{ttest}(X, i, j) = \n","\\frac{\n","    P(X, i, j) - \\big(P(X, i, *)P(X, *, j)\\big)\n","}{\n","\\sqrt{(P(X, i, *)P(X, *, j))}\n","}$$\n","\n","where $P(X, i, j)$ is $X_{ij}$ divided by the total values in $X$, $P(X, i, *)$ is the sum of the values in row $i$ of $X$ divided by the total values in $X$, and $P(X, *, j)$ is the sum of the values in column $j$ of $X$ divided by the total values in $X$.\n","\n","Your task: implement this reweighting scheme. You can use `test_ttest_implementation` below to check that your implementation is correct.  You do not need to use this for any evaluations, though we hope you will be curious enough to do so!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9IPQXKfpBMWP"},"outputs":[],"source":["def ttest(df):\n","    \"\"\"Apply a t-test on each cell in dataframe\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        The dataframe to apply t-test on\n","    \n","    Returns\n","    -------\n","    pd.DataFrame: \n","        return t-test dataframe on each cell in dataframe\n","    \"\"\"\n","    row_sum = df.sum(axis=1)  # sum over all columns (column vector)\n","    col_sum = df.sum(axis=0)  # sum over all rows (row vector)\n","    total_sum = df.values.sum()  # sum of total elements\n","    P_X_ij = df / total_sum\n","    P_X_i = row_sum / total_sum\n","    P_X_j = col_sum / total_sum\n","    ind_prob = np.outer(P_X_i, P_X_j)\n","    ttest_df = (P_X_ij - ind_prob) / np.sqrt(ind_prob)\n","    return ttest_df\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iw2aMCFcBMWP"},"outputs":[],"source":["def test_ttest_implementation(func):\n","    \"\"\"`func` should be `ttest`\"\"\"\n","    X = pd.DataFrame([\n","        [1.,  4.,  3.,  0.],\n","        [2., 43.,  7., 12.],\n","        [5.,  6., 19.,  0.],\n","        [1., 11.,  1.,  4.]])\n","    actual = np.array([\n","        [ 0.04655, -0.01337,  0.06346, -0.09507],\n","        [-0.11835,  0.13406, -0.20846,  0.10609],\n","        [ 0.16621, -0.23129,  0.38123, -0.18411],\n","        [-0.0231 ,  0.0563 , -0.14549,  0.10394]])\n","    predicted = func(X)\n","    assert np.array_equal(predicted.round(5), actual), \\\n","        \"Your ttest result is\\n{}\".format(predicted.round(5))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8yN9y5vBMWP"},"outputs":[],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    test_ttest_implementation(ttest)"]},{"cell_type":"markdown","metadata":{"id":"xLXpdOIwBMWP"},"source":["### Pooled BERT representations [1 point]"]},{"cell_type":"markdown","metadata":{"id":"WaozPQ5xBMWP"},"source":["The notebook [vsm_04_contextualreps.ipynb](vsm_04_contextualreps.ipynb) explores methods for deriving static vector representations of words from the contextual representations given by models like BERT and RoBERTa. The methods are due to [Bommasani et al. 2020](https://www.aclweb.org/anthology/2020.acl-main.431). The simplest of these methods involves processing the words as independent texts and pooling the sub-word representations that result, using a function like mean or max.\n","\n","Your task: write a function `evaluate_pooled_bert` that will enable exploration of this approach. The function should do the following:\n","\n","1. Take as its arguments (a) a word relatedness `pd.DataFrame` `rel_df` (e.g., `dev_df`), (b) a `layer` index (see below), and (c) a `pool_func` value (see below).\n","1. Set up a BERT tokenizer and BERT model based on `'bert-base-uncased'`.\n","1. Use `vsm.create_subword_pooling_vsm` to create a VSM (a `pd.DataFrame`) with the user's values for `layer` and `pool_func`.\n","1. Return the return value of `vsm.word_relatedness_evaluation` using this new VSM, evaluated on `rel_df` with `distfunc` set to its default value.\n","\n","The function `vsm.create_subword_pooling_vsm` does the heavy-lifting. Your task is really just to put these pieces together. The result will be the start of a flexible framework for seeing how these methods do on our task. \n","\n","The function `test_evaluate_pooled_bert` can help you obtain the design we are seeking."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFyimRH0BMWQ"},"outputs":[],"source":["from transformers import BertModel, BertTokenizer\n","\n","def evaluate_pooled_bert(rel_df, layer, pool_func):\n","    bert_weights_name = 'bert-base-uncased'\n","\n","    # Initialize a BERT tokenizer and BERT model based on\n","    # `bert_weights_name`:\n","    ##### YOUR CODE HERE\n","    bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n","    bert_model = BertModel.from_pretrained(bert_weights_name)\n","    # Get the vocabulary from `rel_df`:\n","    ##### YOUR CODE HERE\n","    vocab = list(set(rel_df.word1.values) | set(rel_df.word2.values))\n","    # Use `vsm.create_subword_pooling_vsm` with the user's arguments:\n","    ##### YOUR CODE HERE\n","    pooled_df = vsm.create_subword_pooling_vsm(vocab, bert_tokenizer, bert_model, layer=layer, pool_func=pool_func)\n","    # print(f'hidden shape = {pooled_df.iloc[0].shape}')\n","    # Return the results of the relatedness evalution:\n","    ##### YOUR CODE HERE\n","    pooled_bert_pred_df, pooled_bert_rho = vsm.word_relatedness_evaluation(rel_df, pooled_df)\n","    return pooled_bert_pred_df, pooled_bert_rho\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXtpXo-FBMWQ"},"outputs":[],"source":["def test_evaluate_pooled_bert(func):\n","    import torch\n","    rel_df = pd.DataFrame([\n","        {'word1': 'porcupine', 'word2': 'capybara', 'score': 0.6},\n","        {'word1': 'antelope', 'word2': 'springbok', 'score': 0.5},\n","        {'word1': 'llama', 'word2': 'camel', 'score': 0.4},\n","        {'word1': 'movie', 'word2': 'play', 'score': 0.3}])\n","    layer = 2\n","    pool_func = vsm.max_pooling\n","    # pool_func = vsm.mean_pooling\n","    pred_df, rho = evaluate_pooled_bert(rel_df, layer, pool_func)\n","    rho = round(rho, 2)\n","    expected_rho = 0.40\n","    assert rho == expected_rho, \\\n","        \"Expected rho={}; got rho={}\".format(expected_rho, rho)\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250,"referenced_widgets":["fc500163b03549f38aab0d07bad033f3","32c5071a883a4c68861a505e269c5a34","b5d0bde0d0184f3b8bee3e95624c8310","ff6506d0f3b74822a017790a269d17d2","83290fb933314d82bc57cac6aacecb07","8d2661f45f9e4b7095906fd309b0e5b8","087196e5df74411892e47ece8f64628b","1d7fe88eda7449db9dc382f7581b4a66","7e4920e0d6084141bdc34bb68d2aae1d","58cf09c5d73047aea0194a4eb8e42579","c02b76a255c54d459f893dce5bdab3b6","43106d14cc914c5e88a30a888d5ae008","38381a6278dd4a5286b99265616c96fa","70ec790391854c4291365a342996022c","14a759442ee24642a31e5ba5582e4d58","0dffb412f54a4fbfa35025085622359e","af3311a3afb6484fb9ff5f11c02f28b3","7f87d23d43644fdd8e9098bc9cc3ee59","e555e7d71d5b44fb965bc0a98a337b9f","84bfc9609bef46748a3db8f73b1c5c65","3f036f16e7de47c0890fa70b2ed80108","bc69e0d1317041fe8ac0e5e4740e5222","d506c61dfab84868921252ae94f16782","74b7f8bdbdfc4124ba126fed83e55d1c","aa73888ba4bc44d39b891dfa5e19c062","23e1e595eb64435c85e864a43ea9f322","7f529f38c0e549d19daa60adc505631f","db5e0b25601f4cc5a59e360aece24759","aa217383465d4b9f94dcd10f404335be","6a0ca957835d49919efa88e7846b20f2","bd65a917788e4687b582a65f76c05f5c","d99c94cafd08446480c9da5c207fd0ff","fe79718a00934d3887f42e0c0acc4dd8","7c7531d890424eb591f3eb38f891643a","691457150f1b4009aa3dafbf8f892562","ed7f74220a6a4d168753175a0b59ec10","1db53bae52e44c9a88cc9e976ee7954d","1cf67597b741419bab9e9d3b9049d7cc","b2db28927d9e430c99c2bb2ba65634f1","52c035eedd1c458d91c4a549901fa8ae","9032cf0caddf41ada135d0f8e352fbb4","4810d5365ad44dd9a90cf5e6aef98f6c","2f06412341fd4ca5aaa14fe58338969d","d6cc54b5612d4c4db9a3c1d5f3b2054a","50524544ab024cf69c0a081aa394b54f","31c5b6bb37d741c198742ab2825eb815","930ab3a5c7e44b84b7a6aede3aa4c5ca","bcded5ff5dab45afb298f108689a8328","859fcbb330824e40ab3c729da3b2d543","e3967a2ee3204cca8ab2e008176f1a46","8aedad4c9dab4872856111a3b5829685","a499a877b4cd4f36bb7aa27ea30d26c9","16df3cd757fc4f4f906dbd8b1c972500","3d7ce00ba06c48e29f66f570852dd46a","99b0df71fe854dae801442e8fd65caf5"]},"id":"ffQ_sJ-pBMWQ","executionInfo":{"status":"ok","timestamp":1641740789405,"user_tz":-120,"elapsed":14427,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"75c01e2c-2256-4c21-9d16-bc1d2f066a43"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc500163b03549f38aab0d07bad033f3","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43106d14cc914c5e88a30a888d5ae008","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d506c61dfab84868921252ae94f16782","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c7531d890424eb591f3eb38f891643a","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50524544ab024cf69c0a081aa394b54f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    test_evaluate_pooled_bert(evaluate_pooled_bert)"]},{"cell_type":"markdown","metadata":{"id":"W5AAHyczBMWQ"},"source":["### Learned distance functions [2 points]"]},{"cell_type":"markdown","metadata":{"id":"g--wRxsABMWT"},"source":["The presentation thus far leads one to assume that the `distfunc` argument used in the experiments will be a standard vector distance function like `vsm.cosine` or `vsm.euclidean`. However, the framework itself simply requires that this function map two fixed-dimensional vectors to a real number. This opens up a world of possibilities. This question asks you to dip a toe in these waters.\n","\n","Your task: write a function `run_knn_score_model` for models in this class. The function should:\n","\n","1. Take as its arguments (a) a VSM dataframe `vsm_df`, (b) a relatedness dataset (e.g., `dev_df`), and (c) a `test_size` value between 0.0 and 1.0 that can be passed directly to `train_test_split` (see below).\n","1. Create a feature matrix `X`: each word pair in `dev_df` should be represented by the concatenation of the vectors for word1 and word2 from `vsm_df`.\n","1. Create a score vector `y`, which is just the `score` column in `dev_df`.\n","1. Split the dataset `(X, y)` into train and test portions using [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n","1. Train an [sklearn.neighbors.KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) model on the train split from step 4, with default hyperparameters.\n","1. Return the value of the `score` method of the trained `KNeighborsRegressor` model on the test split from step 4.\n","\n","The functions `test_knn_feature_matrix` and `knn_represent` will help you test the crucial representational aspects of this.\n","\n","Note: if you decide to apply this approach to our task as part of an original system, recall that `vsm.create_subword_pooling_vsm` returns `-d` where `d` is the value computed by `distfunc`, since it assumes that `distfunc` is a distance value of some kind rather than a relatedness/similarity value. Since most regression models will return positive scores for positive associations, you will probably want to undo this by having your `distfunc` return the negative of its value."]},{"cell_type":"code","source":["dev_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"fzSQn-MPECSQ","executionInfo":{"status":"ok","timestamp":1641740789408,"user_tz":-120,"elapsed":8,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"80304265-0a78-4e30-ecfc-d793ce9ff1b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-8eba9cb7-51b6-4f6d-b067-831c26ab87a7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word1</th>\n","      <th>word2</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>abandon</td>\n","      <td>button</td>\n","      <td>0.18</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>abandon</td>\n","      <td>consigning</td>\n","      <td>0.40</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>abandon</td>\n","      <td>crane</td>\n","      <td>0.16</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>abandon</td>\n","      <td>ditch</td>\n","      <td>0.63</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>abandon</td>\n","      <td>left</td>\n","      <td>0.57</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8eba9cb7-51b6-4f6d-b067-831c26ab87a7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8eba9cb7-51b6-4f6d-b067-831c26ab87a7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8eba9cb7-51b6-4f6d-b067-831c26ab87a7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     word1       word2  score\n","0  abandon      button   0.18\n","1  abandon  consigning   0.40\n","2  abandon       crane   0.16\n","3  abandon       ditch   0.63\n","4  abandon        left   0.57"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XqHCdBZ-BMWT"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsRegressor\n","\n","def run_knn_score_model(vsm_df, dev_df, test_size=0.20):\n","\n","    # Complete `knn_feature_matrix` for this step.\n","    ##### YOUR CODE HERE\n","    X = knn_feature_matrix(vsm_df, dev_df)\n","\n","\n","    # Get the values of the 'score' column in `dev_df`\n","    # and store them in a list or array `y`.\n","    ##### YOUR CODE HERE\n","    y = dev_df['score']\n","\n","    # Use `train_test_split` to split (X, y) into train and\n","    # test protions, with `test_size` as the test size.\n","    ##### YOUR CODE HERE\n","    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size)\n","\n","\n","    # Instantiate a `KNeighborsRegressor` with default arguments:\n","    ##### YOUR CODE HERE\n","    knr = KNeighborsRegressor()\n","    # Fit the model on the training data:\n","    ##### YOUR CODE HERE\n","    knr.fit(X_tr, y_tr)\n","\n","\n","    # Return the value of `score` for your model on the test split\n","    # you created above:\n","    ##### YOUR CODE HERE\n","    predicted_scores = knr.predict(X_te)\n","    return predicted_scores\n","\n","\n","def knn_feature_matrix(vsm_df, rel_df):\n","    # Complete `knn_represent` and use it to create a feature\n","    # matrix `np.array`:\n","    ##### YOUR CODE HERE\n","    X = knn_represent(rel_df[\"word1\"], rel_df[\"word2\"], vsm_df)\n","    return X\n","    # for row in rel_df[[\"word1\", \"word2\"]].iterrow():\n","    #     pair_represntation = knn_represent(word1, word2, vsm_df)\n","\n","    # rel_df.apply(lambda row: row[0], row[1], axis=1)\n","\n","\n","\n","def knn_represent(word1, word2, vsm_df):\n","    # Use `vsm_df` to get vectors for `word1` and `word2`\n","    # and concatenate them into a single vector:\n","    ##### YOUR CODE HERE\n","    if type(word1) == str:  # concatentate on the row dimension (1-D array) (single row representation)\n","      knn_pair_representations = np.concatenate([vsm_df.loc[word1].values, vsm_df.loc[word2].values], axis=0)\n","    else:  # get all representations at once\n","        knn_pair_representations = np.concatenate([vsm_df.loc[word1].values, vsm_df.loc[word2].values], axis=1)\n","    return knn_pair_representations\n","    # pair_representation = np.concatenate([vsm_df.loc[word1].values, vsm_df.loc[word2].values], axis=0)\n","    # return pair_representation\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muQirNZIBMWU"},"outputs":[],"source":["def test_knn_feature_matrix(func):\n","    rel_df = pd.DataFrame([\n","        {'word1': 'w1', 'word2': 'w2', 'score': 0.1},\n","        {'word1': 'w1', 'word2': 'w3', 'score': 0.2}])\n","    vsm_df = pd.DataFrame([\n","        [1, 2, 3.],\n","        [4, 5, 6.],\n","        [7, 8, 9.]], index=['w1', 'w2', 'w3'])\n","    expected = np.array([\n","        [1, 2, 3, 4, 5, 6.],\n","        [1, 2, 3, 7, 8, 9.]])\n","    result = func(vsm_df, rel_df)\n","    assert np.array_equal(result, expected), \\\n","        \"Your `knn_feature_matrix` returns: {}\\nWe expect: {}\".format(\n","        result, expected)\n","\n","def test_knn_represent(func):\n","    vsm_df = pd.DataFrame([\n","        [1, 2, 3.],\n","        [4, 5, 6.],\n","        [7, 8, 9.]], index=['w1', 'w2', 'w3'])\n","    result = func('w1', 'w3', vsm_df)\n","    expected = np.array([1, 2, 3, 7, 8, 9.])\n","    assert np.array_equal(result, expected), \\\n","        \"Your `knn_represent` returns: {}\\nWe expect: {}\".format(\n","        result, expected)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U85-82GjBMWU"},"outputs":[],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    test_knn_represent(knn_represent)\n","    test_knn_feature_matrix(knn_feature_matrix)"]},{"cell_type":"markdown","metadata":{"id":"io5qlBnABMWU"},"source":["### Your original system [3 points]\n","\n","This question asks you to design your own model. You can of course include steps made above (ideally, the above questions informed your system design!), but your model should not be literally identical to any of the above models. Other ideas: retrofitting, autoencoders, GloVe, subword modeling, ... \n","\n","Requirements:\n","\n","1. Your system must work with `vsm.word_relatedness_evaluation`. You are free to specify the VSM and the value of `distfunc`.\n","\n","1. Your code must be self-contained, so that we can work with your model directly in your homework submission notebook. If your model depends on external data or other resources, please submit a ZIP archive containing these resources along with your submission.\n","\n","In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies. We also ask that you report the best score your system got during development, just to help us understand how systems performed overall."]},{"cell_type":"code","source":["# AE (after LSA)\n","from torch_autoencoder import TorchAutoencoder\n","import torch.nn as nn\n","\n","\n","def run_ae_pipeline(df, hidden_dim=50, hidden_activation=nn.Tanh()):  # relu?\n","    # ppmi_df = vsm.pmi(count_df, positive=True)  # get ppmi weights\n","    # lsa_df = vsm.lsa(ppmi_df, k=k)  # appy dimensionality reduction with LSA\n","    ae = TorchAutoencoder(hidden_dim=hidden_dim, hidden_activation=hidden_activation)\n","    ae_df = ae.fit(df)\n","    ae_pred_df, ae_rho = vsm.word_relatedness_evaluation(dev_df, ae_df)  # default distfunc=consine\n","    return ae_pred_df, ae_rho\n","\n","\n","header = ['hidden_size', 'activation', 'rho']\n","results = []\n","hidden_dims = [50, 100]\n","activation_dict = {'tanh': nn.Tanh(), 'relu': nn.ReLU()}\n","K = 200\n","ppmi_df = vsm.pmi(count_df_giga20, positive=True)  # get ppmi weights\n","lsa_df = vsm.lsa(ppmi_df, k=K)  # appy dimensionality reduction with LSA\n"],"metadata":{"id":"_VYbtw7jVSrH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hyperparameter search over AE model (hidden size and activation)\n","for hidden_dim in hidden_dims:\n","    for activation_name, activation_func in activation_dict.items():\n","        ae_pred_df, ae_rho = run_ae_pipeline(lsa_df, hidden_dim, activation_func)\n","        results.append((hidden_dim, activation_name, round(ae_rho, 3)))\n","\n","df_ae = pd.DataFrame(data=results, columns=header)\n","df_ae"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192},"id":"NMGdr1xYZCtI","executionInfo":{"status":"ok","timestamp":1641741775339,"user_tz":-120,"elapsed":202983,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"b882ba71-da05-4fe0-fd26-0d22ab6b33e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Stopping after epoch 279. Training loss did not improve more than tol=1e-05. Final error is 2.5548931062221527."]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-821d8ef5-e9c2-489d-8001-972642695159\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hidden_size</th>\n","      <th>activation</th>\n","      <th>rho</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50</td>\n","      <td>tanh</td>\n","      <td>0.594</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>relu</td>\n","      <td>0.599</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100</td>\n","      <td>tanh</td>\n","      <td>0.618</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>100</td>\n","      <td>relu</td>\n","      <td>0.624</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-821d8ef5-e9c2-489d-8001-972642695159')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-821d8ef5-e9c2-489d-8001-972642695159 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-821d8ef5-e9c2-489d-8001-972642695159');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   hidden_size activation    rho\n","0           50       tanh  0.594\n","1           50       relu  0.599\n","2          100       tanh  0.618\n","3          100       relu  0.624"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["# transformer (more sophisticated pretrained model)\n","from transformers import BertModel, BertTokenizer\n","\n","def evaluate_pooled_bert(rel_df, layer, pool_func):\n","    bert_weights_name = 'bert-base-uncased'\n","\n","    # Initialize a BERT tokenizer and BERT model based on\n","    # `bert_weights_name`:\n","    ##### YOUR CODE HERE\n","    bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n","    bert_model = BertModel.from_pretrained(bert_weights_name)\n","    # Get the vocabulary from `rel_df`:\n","    ##### YOUR CODE HERE\n","    vocab = list(set(rel_df.word1.values) | set(rel_df.word2.values))\n","    # Use `vsm.create_subword_pooling_vsm` with the user's arguments:\n","    ##### YOUR CODE HERE\n","    pooled_df = vsm.create_subword_pooling_vsm(vocab, bert_tokenizer, bert_model, layer=layer, pool_func=pool_func)\n","    # print(f'hidden shape = {pooled_df.iloc[0].shape}')\n","    # Return the results of the relatedness evalution:\n","    ##### YOUR CODE HERE\n","    pooled_bert_pred_df, pooled_bert_rho = vsm.word_relatedness_evaluation(rel_df, pooled_df)\n","    return pooled_bert_pred_df, pooled_bert_rho\n","\n","\n","header = ['pooling', 'rho']\n","results = []\n","pool_func_dict = {'max': vsm.max_pooling, 'mean': vsm.mean_pooling}\n","for pool_name, pool_func in pool_func_dict.items():\n","    pooled_bert_pred_df, pooled_bert_rho = evaluate_pooled_bert(dev_df, layer=-1, pool_func=pool_func)\n","    results.append((pool_name, pooled_bert_rho))\n","\n","df_bert = pd.DataFrame(data=results, columns=header)\n","df_bert"],"metadata":{"id":"w_p6_TCMVUHn","colab":{"base_uri":"https://localhost:8080/","height":239},"executionInfo":{"status":"ok","timestamp":1641742394818,"user_tz":-120,"elapsed":327544,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"c0415ac2-4344-4a9c-e72e-133c183c54fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-836d168d-7631-4821-acb6-c7051709e73f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pooling</th>\n","      <th>rho</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>max</td>\n","      <td>0.228898</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>mean</td>\n","      <td>0.233114</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-836d168d-7631-4821-acb6-c7051709e73f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-836d168d-7631-4821-acb6-c7051709e73f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-836d168d-7631-4821-acb6-c7051709e73f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  pooling       rho\n","0     max  0.228898\n","1    mean  0.233114"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9fbIECiBMWU"},"outputs":[],"source":["# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n","#   1) Textual description of your system.\n","#   2) The code for your original system.\n","#   3) The score achieved by your system in place of MY_NUMBER.\n","#        With no other changes to that line.\n","#        You should report your score as a decimal value <=1.0\n","# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n","\n","# NOTE: MODULES, CODE AND DATASETS REQUIRED FOR YOUR ORIGINAL SYSTEM\n","# SHOULD BE ADDED BELOW THE 'IS_GRADESCOPE_ENV' CHECK CONDITION. DOING\n","# SO ABOVE THE CHECK MAY CAUSE THE AUTOGRADER TO FAIL.\n","\n","# START COMMENT: Enter your system description in this cell.\n","# My peak score was: MY_NUMBER\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    pass\n","\n","\n","\n","# STOP COMMENT: Please do not remove this comment."]},{"cell_type":"markdown","metadata":{"id":"2yotblUEBMWV"},"source":["## Bake-off [1 point]\n","\n","For the bake-off, you simply need to evaluate your original system on the file \n","\n","`wordrelatedness/cs224u-wordrelatedness-test-unlabeled.csv`\n","\n","This contains only word pairs (no scores), so `vsm.word_relatedness_evaluation` will simply make predictions without doing any scoring. Use that function to make predictions with your original system, store the resulting `pred_df` to a file, and then upload the file as your bake-off submission.\n","\n","The following function should be used to conduct this evaluation:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AsBaXYp4BMWV"},"outputs":[],"source":["def create_bakeoff_submission(\n","        vsm_df,\n","        distfunc,\n","        output_filename=\"cs224u-wordrelatedness-bakeoff-entry.csv\"):\n","\n","    test_df = pd.read_csv(\n","        os.path.join(DATA_HOME, \"cs224u-wordrelatedness-test-unlabeled.csv\"))\n","\n","    pred_df, _ = vsm.word_relatedness_evaluation(test_df, vsm_df, distfunc=distfunc)\n","\n","    pred_df.to_csv(output_filename)"]},{"cell_type":"markdown","metadata":{"id":"veORcLn8BMWV"},"source":["For example, if `count_df` were the VSM for my system, and I wanted my distance function to be `vsm.euclidean`, I would do"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iw_pkEJnBMWV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641742921150,"user_tz":-120,"elapsed":23854,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"1702033d-1b64-446b-a2c7-0aa72edfb63a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Stopping after epoch 206. Training loss did not improve more than tol=1e-05. Final error is 2.576342523097992."]}],"source":["# This check ensure that the following code only runs on the local environment only.\n","# The following call will not be run on the autograder environment.\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    # pass\n","    # create_bakeoff_submission(count_df, vsm.euclidean)\n","    ae = TorchAutoencoder(hidden_dim=100, hidden_activation=nn.ReLU())\n","    ae_df = ae.fit(lsa_df)\n","    create_bakeoff_submission(ae_df, vsm.cosine)"]},{"cell_type":"markdown","metadata":{"id":"IMzQLV0pBMWV"},"source":["This creates a file `cs224u-wordrelatedness-bakeoff-entry.csv` in the current directory. That file should be uploaded as-is. Please do not change its name.\n","\n","Only one upload per team is permitted, and you should do no tuning of your system based on what you see in `pred_df` – you should not study that file in anyway, beyond perhaps checking that it contains what you expected it to contain. The upload function will do some additional checking to ensure that your file is well-formed.\n","\n","People who enter will receive the additional homework point, and people whose systems achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.\n","\n","Late entries will be accepted, but they cannot earn the extra 0.5 points."]},{"cell_type":"markdown","metadata":{"id":"Jvj-U1VgBMWV"},"source":["## Submission Instruction\n","\n","Submit the following files to gradescope submission\n","\n","- Please do not change the file name as described below\n","- `hw_wordrelatedness.ipynb` (this notebook)\n","- `cs224u-wordrelatedness-bakeoff-entry.csv` (bake-off output)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"hw_wordrelatedness.ipynb","provenance":[],"collapsed_sections":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"fc500163b03549f38aab0d07bad033f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_32c5071a883a4c68861a505e269c5a34","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b5d0bde0d0184f3b8bee3e95624c8310","IPY_MODEL_ff6506d0f3b74822a017790a269d17d2","IPY_MODEL_83290fb933314d82bc57cac6aacecb07"]}},"32c5071a883a4c68861a505e269c5a34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5d0bde0d0184f3b8bee3e95624c8310":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8d2661f45f9e4b7095906fd309b0e5b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_087196e5df74411892e47ece8f64628b"}},"ff6506d0f3b74822a017790a269d17d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1d7fe88eda7449db9dc382f7581b4a66","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e4920e0d6084141bdc34bb68d2aae1d"}},"83290fb933314d82bc57cac6aacecb07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_58cf09c5d73047aea0194a4eb8e42579","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 2.58MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c02b76a255c54d459f893dce5bdab3b6"}},"8d2661f45f9e4b7095906fd309b0e5b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"087196e5df74411892e47ece8f64628b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1d7fe88eda7449db9dc382f7581b4a66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7e4920e0d6084141bdc34bb68d2aae1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58cf09c5d73047aea0194a4eb8e42579":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c02b76a255c54d459f893dce5bdab3b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43106d14cc914c5e88a30a888d5ae008":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_38381a6278dd4a5286b99265616c96fa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_70ec790391854c4291365a342996022c","IPY_MODEL_14a759442ee24642a31e5ba5582e4d58","IPY_MODEL_0dffb412f54a4fbfa35025085622359e"]}},"38381a6278dd4a5286b99265616c96fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70ec790391854c4291365a342996022c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_af3311a3afb6484fb9ff5f11c02f28b3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f87d23d43644fdd8e9098bc9cc3ee59"}},"14a759442ee24642a31e5ba5582e4d58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e555e7d71d5b44fb965bc0a98a337b9f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84bfc9609bef46748a3db8f73b1c5c65"}},"0dffb412f54a4fbfa35025085622359e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3f036f16e7de47c0890fa70b2ed80108","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 644B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc69e0d1317041fe8ac0e5e4740e5222"}},"af3311a3afb6484fb9ff5f11c02f28b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7f87d23d43644fdd8e9098bc9cc3ee59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e555e7d71d5b44fb965bc0a98a337b9f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"84bfc9609bef46748a3db8f73b1c5c65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f036f16e7de47c0890fa70b2ed80108":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bc69e0d1317041fe8ac0e5e4740e5222":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d506c61dfab84868921252ae94f16782":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_74b7f8bdbdfc4124ba126fed83e55d1c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aa73888ba4bc44d39b891dfa5e19c062","IPY_MODEL_23e1e595eb64435c85e864a43ea9f322","IPY_MODEL_7f529f38c0e549d19daa60adc505631f"]}},"74b7f8bdbdfc4124ba126fed83e55d1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa73888ba4bc44d39b891dfa5e19c062":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db5e0b25601f4cc5a59e360aece24759","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa217383465d4b9f94dcd10f404335be"}},"23e1e595eb64435c85e864a43ea9f322":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6a0ca957835d49919efa88e7846b20f2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd65a917788e4687b582a65f76c05f5c"}},"7f529f38c0e549d19daa60adc505631f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d99c94cafd08446480c9da5c207fd0ff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 455k/455k [00:00&lt;00:00, 6.15MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe79718a00934d3887f42e0c0acc4dd8"}},"db5e0b25601f4cc5a59e360aece24759":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa217383465d4b9f94dcd10f404335be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a0ca957835d49919efa88e7846b20f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bd65a917788e4687b582a65f76c05f5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d99c94cafd08446480c9da5c207fd0ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe79718a00934d3887f42e0c0acc4dd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c7531d890424eb591f3eb38f891643a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_691457150f1b4009aa3dafbf8f892562","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ed7f74220a6a4d168753175a0b59ec10","IPY_MODEL_1db53bae52e44c9a88cc9e976ee7954d","IPY_MODEL_1cf67597b741419bab9e9d3b9049d7cc"]}},"691457150f1b4009aa3dafbf8f892562":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed7f74220a6a4d168753175a0b59ec10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b2db28927d9e430c99c2bb2ba65634f1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_52c035eedd1c458d91c4a549901fa8ae"}},"1db53bae52e44c9a88cc9e976ee7954d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9032cf0caddf41ada135d0f8e352fbb4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4810d5365ad44dd9a90cf5e6aef98f6c"}},"1cf67597b741419bab9e9d3b9049d7cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2f06412341fd4ca5aaa14fe58338969d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 12.0kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d6cc54b5612d4c4db9a3c1d5f3b2054a"}},"b2db28927d9e430c99c2bb2ba65634f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"52c035eedd1c458d91c4a549901fa8ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9032cf0caddf41ada135d0f8e352fbb4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4810d5365ad44dd9a90cf5e6aef98f6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f06412341fd4ca5aaa14fe58338969d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d6cc54b5612d4c4db9a3c1d5f3b2054a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"50524544ab024cf69c0a081aa394b54f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_31c5b6bb37d741c198742ab2825eb815","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_930ab3a5c7e44b84b7a6aede3aa4c5ca","IPY_MODEL_bcded5ff5dab45afb298f108689a8328","IPY_MODEL_859fcbb330824e40ab3c729da3b2d543"]}},"31c5b6bb37d741c198742ab2825eb815":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"930ab3a5c7e44b84b7a6aede3aa4c5ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e3967a2ee3204cca8ab2e008176f1a46","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8aedad4c9dab4872856111a3b5829685"}},"bcded5ff5dab45afb298f108689a8328":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a499a877b4cd4f36bb7aa27ea30d26c9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16df3cd757fc4f4f906dbd8b1c972500"}},"859fcbb330824e40ab3c729da3b2d543":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3d7ce00ba06c48e29f66f570852dd46a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 420M/420M [00:10&lt;00:00, 40.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_99b0df71fe854dae801442e8fd65caf5"}},"e3967a2ee3204cca8ab2e008176f1a46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8aedad4c9dab4872856111a3b5829685":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a499a877b4cd4f36bb7aa27ea30d26c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"16df3cd757fc4f4f906dbd8b1c972500":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d7ce00ba06c48e29f66f570852dd46a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"99b0df71fe854dae801442e8fd65caf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}